{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5eccb9a",
   "metadata": {},
   "source": [
    "#### Connect to gen-ai-hub using langchain\n",
    "\n",
    "Note: Make sure you have created the deployments (e.g. 'gpt-35-turbo') beforehand in AI Launchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60453586-528e-44b9-8f2f-6d7c605f597d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Godmorgen'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.langchain.init_models import init_llm\n",
    "\n",
    "model = 'gpt-35-turbo'\n",
    "llm = init_llm(model, temperature=0., max_tokens=256)\n",
    "\n",
    "prompt = \"\"\"Translate to danish: Guten Morgen\"\"\"\n",
    "llm.invoke(prompt).content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13937861",
   "metadata": {},
   "source": [
    "Optional: Try another of your deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c95ea99e-0f34-4a2b-b025-13fe84bf25ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Godmorgen'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.langchain.init_models import init_llm\n",
    "\n",
    "model = 'gpt-4-32k'\n",
    "llm = init_llm(model, temperature=0., max_tokens=256)\n",
    "\n",
    "prompt = \"\"\"Translate to danish: Guten Morgen\"\"\"\n",
    "llm.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a22ce",
   "metadata": {},
   "source": [
    "Embeddings: Connect to a text embedding model using langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aa4ce8a-e113-4417-b6cc-23cdbc0fca1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.01314815171259852"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.langchain.init_models import init_embedding_model\n",
    "\n",
    "embeddings = init_embedding_model('text-embedding-ada-002')\n",
    "\n",
    "text = 'Every decoding is another encoding.'\n",
    "response = embeddings.embed_query(text)\n",
    "\n",
    "response[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fe8104",
   "metadata": {},
   "source": [
    "Connect using langchain and proxy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "122bb6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Godmorgen'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.langchain.init_models import init_llm\n",
    "from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# note: proxy_client is optional\n",
    "proxy_client = get_proxy_client('gen-ai-hub')\n",
    "\n",
    "chat = ChatOpenAI(proxy_model_name=\"gpt-35-turbo\", proxy_client=proxy_client, temperature=0)\n",
    "\n",
    "prompt = \"\"\"Translate to danish: Guten Morgen\"\"\"\n",
    "chat.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "810234d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \"God morgen\"'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.langchain.openai import OpenAI \n",
    "\n",
    "from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client\n",
    "proxy_client = get_proxy_client('gen-ai-hub')\n",
    "\n",
    "# non-chat model\n",
    "model_name = \"tiiuae--falcon-40b-instruct\"\n",
    "\n",
    "llm = OpenAI(proxy_model_name=model_name, proxy_client=proxy_client)  # can be used as usual with langchain\n",
    "\n",
    "prompt = \"\"\"Translate \"Guten Morgen\" to danish:\"\"\"\n",
    "\n",
    "llm.invoke(prompt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
